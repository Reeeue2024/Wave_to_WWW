# [ URL Modules ] External Resource Analyzer

import sys
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import tldextract

class HtmlUrl:
    """
    IN : input_url (str)
    OUT : scan ê²°ê³¼ ì¶œë ¥ (Phishing ê°€ëŠ¥ì„± í™•ë¥ , íƒì§€ ì—¬ë¶€)
    """
    def __init__(self, input_url):
        self.input_url = input_url

    def get_registered_domain(self, url: str) -> str:
        ext = tldextract.extract(url)
        return f"{ext.domain}.{ext.suffix}"

    def is_external_resource(self, base_url: str, resource_url: str) -> bool:
        base_domain = self.get_registered_domain(base_url)
        resource_domain = self.get_registered_domain(resource_url)
        return base_domain != resource_domain

    """
    IN : self.input_url
    OUT : í™”ë©´ ì¶œë ¥ (ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ ë¹„ìœ¨, í”¼ì‹± ì—¬ë¶€)
    """
    def scan(self):
        print("ğŸ“¦ External Resource Analyzer Module Start.\n")

        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/121.0.0.0 Safari/537.36"
        }

        try:
            response = requests.get(self.input_url, headers=headers, timeout=5, allow_redirects=True)
            response.raise_for_status()
            html = response.text
        except requests.exceptions.RequestException as e:
            print(f"[âŒ] URL ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
            sys.exit(1)

        soup = BeautifulSoup(html, 'html.parser')
        base_url = self.input_url

        resources = []

        # ë¦¬ì†ŒìŠ¤ ì¶”ì¶œ
        for tag in soup.find_all('link', href=True):
            resources.append(tag['href'])
        for tag in soup.find_all('script', src=True):
            resources.append(tag['src'])
        for tag in soup.find_all('img', src=True):
            resources.append(tag['src'])

        print(f"ğŸ” ì´ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ê°œìˆ˜: {len(resources)}")

        if not resources:
            print("\nâœ… ë¦¬ì†ŒìŠ¤ê°€ ì—†ì–´ í”¼ì‹± ê°€ëŠ¥ì„± ë‚®ìŒ (0%)")
            return

        # ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ íƒì§€
        external_count = sum(
            self.is_external_resource(base_url, r) or r.startswith('http://')
            for r in resources
        )

        ratio = external_count / len(resources)
        probability = round(ratio * 100, 2)
        is_phishing = probability > 50.0

        print(f"ğŸš¨ ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ ë¹„ìœ¨: {external_count}/{len(resources)}")
        print(f"\nğŸ“Š í”¼ì‹± ê°€ëŠ¥ì„±: {probability}%")
        print(f"ğŸ” ìµœì¢… íŒë‹¨: {'Phishing O (ìœ„í—˜)' if is_phishing else 'Phishing X (ì•ˆì „)'}")
        print("\nâœ… Module End.")

# Module Main
if __name__ == "__main__":
    # Input : URL
    if len(sys.argv) != 2:
        print("ì‚¬ìš©ë²•: python3 external_resource_analyzer.py <URL>")
        sys.exit(1)

    input_url = sys.argv[1]
    module = HtmlUrl(input_url)
    module.scan()
